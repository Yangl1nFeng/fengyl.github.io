![my_photo](https://github.com/user-attachments/assets/ebad67d0-a64a-4f05-a25a-27b24674ed7c)---
permalink: /
title: ""
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

My name is Yanglin Feng (å¥‰ä»°éºŸ). Iâ€™m a Ph.D. student (since 2024) at the College of Computer Science, Sichuan University, fortunately advised by Prof. [Dezhong Peng](https://cs.scu.edu.cn/info/1282/13563.htm) and Prof. [Peng Hu](https://penghu-cs.github.io/).

My research interests mainly focus on multimodal learning and cross-domain learning. Recently, Iâ€™ve been conducting research related to 3D vision & language.

- Multimodal Learning: Cross-modal retrieval with noisy labels/correspondence
- Cross-domain Learning: Unsupervised domain adaptation and cross-domain retrieval
- 3D Vision & Language: Pointcloud-text matching and cross-scene object reasoning

ðŸŽ‡News
======
- \[**Publications**\]: 2025.1.19, one paper was accepted by IEEE Transactions on Multimedia (TMM 2025). Thanks to all coauthors! âœŒ
- \[**Publications**\]: 2024.12.10, one paper was accepted by AAAI Conference on Artificial Intelligence (AAAI 2025). Congrats to Ziniu and coauthors! ðŸŽ‰
- \[**Publications**\]: 2023.7.26, one paper was accepted by ACM Multimedia (ACM MM 2023). Thanks to all coauthors! âœŒ
- \[**Publications**\]: 2023.2.28, one paper was accepted by IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2023). Thanks to all coauthors! âœŒ
